{
  "data_processing_home_jobs_tile_title": "Jobs",
  "data_processing_home_notebooks_tile_title": "Notebooks for Apache Spark™",
  "data_processing_home_button_new_notebook": "Notebook erstellen",
  "data_processing_home_go_to_notebooks": "Alle Notebooks anzeigen",
  "data_processing_home_button_new_job": "Neuen Job starten",
  "data_processing_home_go_to_jobs": "Alle Jobs anzeigen",
  "data_processing_home_info_jobs": "Starten Sie Jobs mit Apache Spark ganz nach Bedarf, indem Sie festlegen, wie viel RAM und vCPU verwendet werden soll. Laden Sie Ihren Code im JAR- oder Python-Format in einen Swift-Container hoch und führen Sie ihn aus, indem Sie einen Job absenden. Mit Logs und Metriken können Sie die Ausführung Ihres Jobs in Echtzeit mitverfolgen.",
  "data_processing_home_info_notebooks": "Starten Sie Ihre Jupyter Notebooks in der Cloud und, dank Python-Kernel für Apache Spark, starten Sie Ihre Data-Processing-Jobs nach Bedarf direkt von Ihren Notebooks aus.",
  "data_processing_home_spark_trademark": ", Spark, Apache, das Apache-Logo und das Logo des Apache-Spark-Projekts sind Marken der Apache Software Foundation."
}
