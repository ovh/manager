{
  "pci_app_add_resources_usecase": "Use cases",
  "pci_app_add_resources_usecase_item_cpu": "Standard deployment (CPU resources)",
  "pci_app_add_resources_usecase_item_cpu_description": "Excellent quality-price ratio for inference from standard machine learning models. Less expensive, but still very efficient if your model contains a limited number of parameters, with very quick scaling. Choose up to 12 CPUs and 10 replicas for high availability.",
  "pci_app_add_resources_usecase_item_gpu": "High-performance inference (GPU resources)",
  "pci_app_add_resources_usecase_item_gpu_description": "Better performance for inference of large machine learning models, especially deep learning models with a high number of parameters. Up to 4 GPUs and 10 replicas can be selected for high availability.",
  "pci_app_add_resources_proposed_title": "Available resource ranges",
  "pci_app_add_resources_proposed_cpu_description": "Template: {{resourceDescription}}",
  "pci_app_add_resources_proposed_ram": "RAM: {{ram}}",
  "pci_app_add_resources_proposed_cores_single": "CPU: {{cores}} vCore",
  "pci_app_add_resources_proposed_cores": "CPU: {{cores}} vCores",
  "pci_app_add_resources_proposed_storage": "Local storage: {{memory}} SSD",
  "pci_app_add_resources_proposed_bandwidth_public": "Public network: {{bandwidth}}/s",
  "pci_app_add_resources_proposed_bandwidth_private": "Private network: {{bandwidth}}/s",
  "pci_app_add_resources_proposed_resource_price_by_resource": "ex. VAT/hour",
  "pci_app_add_resources_proposed_type_gpu_description": "GPU instances available",
  "pci_app_add_resources_proposed_type_cpu_description": "CPU instances available",
  "pci_app_add_resources_scaling": "Scaling",
  "pci_app_add_resources_scaling_description": "Pick the deployment strategy that best suits your app. Choose a fixed size for the number of replicas your app will be deployed on, or specify a minimum and maximum number of replicas for your deployments. This will dynamically optimise performance, and adapt to the number of requests via the auto-scaling option.",
  "pci_app_add_resources_scaling_description_link": "More information",
  "pci_app_add_resources_scaling_description_message": "Please note that the number of replica nodes you choose will increase the number of resources you use.",
  "pci_app_add_resources_scaling_switch_label": "Strategy",
  "pci_app_add_resources_scaling_switch_label_enabled": "Auto-scaling enabled",
  "pci_app_add_resources_scaling_switch_label_disabled": "Auto-scaling disabled",
  "pci_app_add_resources_scaling_replicas": "Number of replicas your app will be deployed on",
  "pci_app_add_resources_scaling_replicas_help_text": "Deploy on a minimum of 2 replicas for high availability",
  "pci_app_add_resources_scaling_min_replicas": "Minimum replicas",
  "pci_app_add_resources_scaling_max_replicas": "Maximum replicas",
  "pci_app_add_resources_scaling_trigger_resource": "Metric monitored",
  "pci_app_add_resources_scaling_trigger_resource_help_text": "The metric that will act as the trigger for auto-scaling",
  "pci_app_add_resources_scaling_trigger_threshold": "Trigger threshold (%)",
  "pci_app_add_resources_scaling_trigger_threshold_help_text": "The metric value, in percent.",
  "pci_app_add_resources_scaling_price_warning": "The total price of the deployment is calculated based on the minimum number of replicas selected. Please note that this cost may increase when auto-scaling is enabled.",
  "pci_app_add_resources_total": "Total deployment price",
  "pci_app_add_resources_resource_price": "Resource price",
  "pci_app_add_resources_partner_price": "Licence price"
}